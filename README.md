# Simple nextflow

Example of a simple workflow that consists of a

* preprocessing step,
* a processing step that requires multiple cores as well as a conda
  environment, and
* a postprocessing step.

It is only intended to be used in a demo to illustrate how to execute a
nextflow workflow directly from a GitHub repository.  It is intended to be
used in the ["Workflows for HPC training]


## What is it?

1. `preprocess.py`: Python script for the preprocessing step.  It generates a
   file with a given number of 2D-points.
1. `process.py`: Python script for the processing step.  It reads the file
   generated by the preprocessing step, and computes the distance between all
   pairs of points.  It uses multiple cores to do so.
1. `postprocess.py`: Python script for the postprocessing step.  It reads the
   file generated by the processing step, and computes the distribution of the
   distances.
1. `main.nf`: Nextflow script defining the workflow.
1. `nextflow.config`: Nextflow configuration file that defines three profiles,
   a `standard` one that only enables conda, a `laptop` profile that uses
   multiple cores, and a `cluster` profile that uses the `slurm` executor.
1. `conda_environment.yml`: conda environment file to create the environment
   required by the `Process` step of the workflow.
1. `conda_init.sh`: Bash script to initialize the shell for conda use.
   **Note:** this script is only sourced when running the workflow with the
   `slurm` executor, i.e., with the `cluster` profile.


## How to use it?

To run the workflow locally,
```bash
$ nextflow run main.nf -profile laptop
```

To run the workflow on a Slurm cluster,
```bash
$ nextflow run main.nf -profile cluster
```

To run the workflow directory from the GitHub repository,
```bash
$ nextflow run gjbex/SimpleNextflow -profile laptop
```

To run with a different number of points,
```bash
$ nextflow run main.nf -profile laptop --nr_points 3000
```
